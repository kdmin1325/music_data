{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Demo usage</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beat tracking from MIDI performance recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 12\u001B[0m\n\u001B[1;32m      9\u001B[0m processor \u001B[38;5;241m=\u001B[39m RNNJointBeatProcessor()\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Process the MIDI recording to the beat predictions\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m beats_pred, downbeats_pred \u001B[38;5;241m=\u001B[39m \u001B[43mprocessor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmidi_recording\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Ground truth beats\u001B[39;00m\n\u001B[1;32m     15\u001B[0m midi_data \u001B[38;5;241m=\u001B[39m pm\u001B[38;5;241m.\u001B[39mPrettyMIDI(midi_recording)\n",
      "File \u001B[0;32m~/Desktop/git_files/data_platform/source_codes/server_source_codes/web_application_server_codes/midi_to_score/pm2s/features/_processor.py:38\u001B[0m, in \u001B[0;36mMIDIProcessor.process\u001B[0;34m(self, midi_file, **kwargs)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# Read MIDI file into note sequence\u001B[39;00m\n\u001B[0;32m---> 38\u001B[0m note_seq \u001B[38;5;241m=\u001B[39m \u001B[43mread_note_sequence\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmidi_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_note_seq(note_seq)\n",
      "File \u001B[0;32m~/Desktop/git_files/data_platform/source_codes/server_source_codes/web_application_server_codes/midi_to_score/pm2s/io/midi_read.py:17\u001B[0m, in \u001B[0;36mread_note_sequence\u001B[0;34m(midi_file, start_time, end_time)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_note_sequence\u001B[39m(midi_file, start_time\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.\u001B[39m, end_time\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m      5\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m    Load MIDI file into note sequence.\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m    note_seq: (numpy.array) in the shape of (n, 4), where n is the number of notes, and 4 is the number of features including (pitch, onset, offset, velocity). The note sequence is sorted by onset time.\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m     midi_data \u001B[38;5;241m=\u001B[39m \u001B[43mpretty_midi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPrettyMIDI\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmidi_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m     notes \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m instrument \u001B[38;5;129;01min\u001B[39;00m midi_data\u001B[38;5;241m.\u001B[39minstruments:\n",
      "File \u001B[0;32m~/miniconda3/envs/server/lib/python3.8/site-packages/pretty_midi/pretty_midi.py:104\u001B[0m, in \u001B[0;36mPrettyMIDI.__init__\u001B[0;34m(self, midi_file, resolution, initial_tempo)\u001B[0m\n\u001B[1;32m     97\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m     98\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTempo, Key or Time signature change events found on \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     99\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero tracks.  This is not a valid type 0 or type 1 \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    100\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMIDI file.  Tempo, Key or Time Signature may be wrong.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    101\u001B[0m             \u001B[38;5;167;01mRuntimeWarning\u001B[39;00m)\n\u001B[1;32m    103\u001B[0m     \u001B[38;5;66;03m# Populate the list of instruments\u001B[39;00m\n\u001B[0;32m--> 104\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_instruments\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmidi_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    107\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresolution \u001B[38;5;241m=\u001B[39m resolution\n",
      "File \u001B[0;32m~/miniconda3/envs/server/lib/python3.8/site-packages/pretty_midi/pretty_midi.py:295\u001B[0m, in \u001B[0;36mPrettyMIDI._load_instruments\u001B[0;34m(self, midi_data)\u001B[0m\n\u001B[1;32m    292\u001B[0m last_note_on \u001B[38;5;241m=\u001B[39m collections\u001B[38;5;241m.\u001B[39mdefaultdict(\u001B[38;5;28mlist\u001B[39m)\n\u001B[1;32m    293\u001B[0m \u001B[38;5;66;03m# Keep track of which instrument is playing in each channel\u001B[39;00m\n\u001B[1;32m    294\u001B[0m \u001B[38;5;66;03m# initialize to program 0 for all channels\u001B[39;00m\n\u001B[0;32m--> 295\u001B[0m current_instrument \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;241m16\u001B[39m, dtype\u001B[38;5;241m=\u001B[39m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint\u001B[49m)\n\u001B[1;32m    296\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m event \u001B[38;5;129;01min\u001B[39;00m track:\n\u001B[1;32m    297\u001B[0m     \u001B[38;5;66;03m# Look for track name events\u001B[39;00m\n\u001B[1;32m    298\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m event\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrack_name\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    299\u001B[0m         \u001B[38;5;66;03m# Set the track name for the current track\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/server/lib/python3.8/site-packages/numpy/__init__.py:305\u001B[0m, in \u001B[0;36m__getattr__\u001B[0;34m(attr)\u001B[0m\n\u001B[1;32m    300\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    301\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn the future `np.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` will be defined as the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    302\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcorresponding NumPy scalar.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    304\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;129;01min\u001B[39;00m __former_attrs__:\n\u001B[0;32m--> 305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(__former_attrs__[attr])\n\u001B[1;32m    307\u001B[0m \u001B[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001B[39;00m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001B[39;00m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001B[39;00m\n\u001B[1;32m    312\u001B[0m \u001B[38;5;66;03m# the full `numpy.testing` namespace\u001B[39;00m\n\u001B[1;32m    313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtesting\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "from pm2s.features.beat import RNNJointBeatProcessor\n",
    "import mir_eval\n",
    "import pretty_midi as pm\n",
    "\n",
    "# Get one MIDI recording from the A_MAPS dataset\n",
    "midi_recording = './test.midi'\n",
    "\n",
    "# Create a beat processor\n",
    "processor = RNNJointBeatProcessor()\n",
    "\n",
    "# Process the MIDI recording to the beat predictions\n",
    "beats_pred, downbeats_pred = processor.process(midi_recording)\n",
    "\n",
    "# Ground truth beats\n",
    "midi_data = pm.PrettyMIDI(midi_recording)\n",
    "beats_targ = midi_data.get_beats()\n",
    "downbeats_targ = midi_data.get_downbeats()\n",
    "\n",
    "# F-measure for beat tracking\n",
    "beats_pred_trimmed = mir_eval.beat.trim_beats(beats_pred)\n",
    "beats_targ_trimmed = mir_eval.beat.trim_beats(beats_targ)\n",
    "f1_beats = mir_eval.beat.f_measure(beats_targ_trimmed, beats_pred_trimmed)\n",
    "\n",
    "# F-measure for downbeat tracking\n",
    "downbeats_pred_trimmed = mir_eval.beat.trim_beats(downbeats_pred)\n",
    "downbeats_targ_trimmed = mir_eval.beat.trim_beats(downbeats_targ)\n",
    "f1_downbeats = mir_eval.beat.f_measure(downbeats_targ_trimmed, downbeats_pred_trimmed)\n",
    "\n",
    "print('F1 score for beat tracking: {:.4f}'.format(f1_beats))\n",
    "print('F1 score for downbeat tracking: {:.4f}'.format(f1_downbeats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'beats_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 23\u001B[0m\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pr\n\u001B[1;32m     22\u001B[0m start_time, end_time \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m80\u001B[39m\n\u001B[0;32m---> 23\u001B[0m beats_pred_seg \u001B[38;5;241m=\u001B[39m \u001B[43mbeats_pred\u001B[49m[np\u001B[38;5;241m.\u001B[39mlogical_and(beats_pred \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m start_time, beats_pred \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m end_time)]\n\u001B[1;32m     24\u001B[0m beats_targ_seg \u001B[38;5;241m=\u001B[39m beats_targ[np\u001B[38;5;241m.\u001B[39mlogical_and(beats_targ \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m start_time, beats_targ \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m end_time)]\n\u001B[1;32m     25\u001B[0m downbeats_pred_seg \u001B[38;5;241m=\u001B[39m downbeats_pred[np\u001B[38;5;241m.\u001B[39mlogical_and(downbeats_pred \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m start_time, downbeats_pred \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m end_time)]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'beats_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot the beat prediction and pianoroll\n",
    "\n",
    "import numpy as np\n",
    "import pretty_midi as pm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_piano_roll(midi_file, start_time, end_time):\n",
    "\n",
    "    pr = np.zeros((128, int((end_time - start_time) * 100)))\n",
    "\n",
    "    for instrument in pm.PrettyMIDI(midi_file).instruments:\n",
    "        for note in instrument.notes:\n",
    "            if note.start >= end_time or note.end <= start_time:\n",
    "                continue\n",
    "            start = int((note.start - start_time) * 100)\n",
    "            end = int((note.end - start_time) * 100)\n",
    "\n",
    "            pr[note.pitch, start:end] = 1\n",
    "    \n",
    "    return pr\n",
    "\n",
    "start_time, end_time = 0, 80\n",
    "beats_pred_seg = beats_pred[np.logical_and(beats_pred >= start_time, beats_pred <= end_time)]\n",
    "beats_targ_seg = beats_targ[np.logical_and(beats_targ >= start_time, beats_targ <= end_time)]\n",
    "downbeats_pred_seg = downbeats_pred[np.logical_and(downbeats_pred >= start_time, downbeats_pred <= end_time)]\n",
    "downbeats_targ_seg = downbeats_targ[np.logical_and(downbeats_targ >= start_time, downbeats_targ <= end_time)]\n",
    "pr_seg = get_piano_roll(midi_recording, start_time, end_time)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.imshow(1-pr_seg, aspect='auto', origin='lower', cmap='gray')\n",
    "for b in beats_pred_seg:\n",
    "    plt.axvline(x=(b - start_time) * 100, ymin=0.75, ymax=1, color='green')\n",
    "for b in beats_targ_seg:\n",
    "    plt.axvline(x=(b - start_time) * 100, ymin=0, ymax=0.25, color='red')\n",
    "for b in downbeats_pred_seg:\n",
    "    plt.axvline(x=(b - start_time) * 100, ymin=0.5, ymax=1, color='green')\n",
    "for b in downbeats_targ_seg:\n",
    "    plt.axvline(x=(b - start_time) * 100, ymin=0, ymax=0.5, color='red')\n",
    "plt.xlabel('Time in milliseconds')\n",
    "plt.title('Upper (green): prediction, Lower (red): ground truth.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantisation from a MIDI performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm2s.features.quantisation import RNNJointQuantisationProcessor\n",
    "\n",
    "# Get one MIDI recording from the A_MAPS dataset\n",
    "midi_recording = '/import/c4dm-05/ll307/datasets/A-MAPS_1.1/MAPS_MUS-bk_xmas1_ENSTDkCl.mid'\n",
    "\n",
    "# Create a quantisation processor\n",
    "processor = RNNJointQuantisationProcessor()\n",
    "\n",
    "# Process the MIDI recording to the beat predictions\n",
    "onset_positions, note_values = processor.process(midi_recording)\n",
    "print('onset positions \\t note values')\n",
    "print('-' * 50)\n",
    "for i in range(20):\n",
    "    print('{:4f} \\t\\t {:.4f}'.format(onset_positions[i], note_values[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand part prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm2s.features.hand_part import RNNHandPartProcessor\n",
    "\n",
    "# Get one MIDI recording from the A_MAPS dataset\n",
    "midi_recording = '../../datasets/A-MAPS_1.1/MAPS_MUS-bk_xmas1_ENSTDkCl.mid'\n",
    "\n",
    "# Create a hand part prediction processor\n",
    "processor = RNNHandPartProcessor()\n",
    "\n",
    "# Predict hand part for each note in the MIDI recording\n",
    "hand_parts = processor.process(midi_recording)\n",
    "\n",
    "print(hand_parts[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time and key signature prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm2s.features.time_signature import CNNTimeSignatureProcessor\n",
    "from pm2s.features.key_signature import RNNKeySignatureProcessor\n",
    "\n",
    "# Get one MIDI recording from the A_MAPS dataset\n",
    "midi_recording = '../../datasets/A-MAPS_1.1/MAPS_MUS-bk_xmas1_ENSTDkCl.mid'\n",
    "\n",
    "# Create time and key processors\n",
    "processor_time_sig = CNNTimeSignatureProcessor()\n",
    "processor_key_sig = RNNKeySignatureProcessor()\n",
    "\n",
    "# Prediction\n",
    "time_signature = processor_time_sig.process(midi_recording)  # Single time signature prediction, assuming time signature does not change over the piece\n",
    "key_signature_changes = processor_key_sig.process(midi_recording)\n",
    "\n",
    "print(\"Time signature:\")\n",
    "print(time_signature)\n",
    "print(\"\\nKey signature changes:\")\n",
    "print(key_signature_changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance MIDI to score conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm2s import crnn_joint_pm2s\n",
    "\n",
    "performance_midi_file = '../../datasets/A-MAPS_1.1/MAPS_MUS-schuim-1_ENSTDkCl.mid'\n",
    "score_midi_file = 'generated_score.mid'\n",
    "\n",
    "# Convert and save the generated score midi\n",
    "crnn_joint_pm2s(performance_midi_file, score_midi_file, start_time=0, end_time=300, include_time_signature=True, include_key_signature=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "513c34b582369c042e4c09b2082a0eee972fc3557bcb2c161c81e814cba2f5b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
